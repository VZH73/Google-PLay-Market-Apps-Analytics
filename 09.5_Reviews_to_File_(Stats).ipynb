{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a single pickle file with all statistical data \n",
    "# from 'ReviewsSentiment' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_appId = pd.read_csv('Dataset//app_data_processed.csv', usecols=['appId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_base = 'Dataset//app_all_review_stats.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d681068bb6514cb1b9c6a2e90080380d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For easier statistical plotting we need to consolidate the data and simplify in order to optimize memory allocation\n",
    "# Date fields are shorten, appId is replaced with dataframe index \n",
    "# Running through the list of appIds and loading app review stats fields \n",
    "# Saving into a separate csv file as it allowes append writing, contrary to pickle\n",
    "try:\n",
    "    while len(tqdm._instances) > 0:\n",
    "        tqdm._instances.pop().close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "file_to = ''.join([file_to_base,'csv'])\n",
    "\n",
    "try:\n",
    "    processed_ids = pd.read_csv(file_to, usecols=['id'])\n",
    "    last_processed_id = df_appId.loc[processed_ids['id'].max()]['appId']\n",
    "    mode = 'a'\n",
    "except:\n",
    "    last_processed_id = ''\n",
    "    mode = 'w'\n",
    "\n",
    "for app_Id in tqdm(list(df_appId[df_appId['appId']>last_processed_id]['appId'])):\n",
    "        \n",
    "    file_from = ''.join(['ReviewsSentiment//',app_Id,'.pkl']) \n",
    "    \n",
    "    if not os.path.exists(file_from):\n",
    "        continue\n",
    "\n",
    "    scores = pd.read_pickle(file_from)\n",
    "\n",
    "    scores['id'] = df_appId.index[df_appId.appId == app_Id][0]\n",
    "    scores['origId'] = scores.index\n",
    "    scores['at'] = pd.to_datetime(scores['at'], format=\"%Y-%m-%d\").dt.strftime(\"%Y%m%d\")\n",
    "    scores['repliedAt'] = scores.apply(lambda x: 0 if pd.isnull(x['repliedAt']) else pd.to_datetime(x['repliedAt'], format=\"%Y-%m-%d\").strftime(\"%Y%m%d\"), axis=1)\n",
    "    scores['reviewLength'] = scores['content'].str.len()\n",
    "\n",
    "    scores.to_csv('Dataset//app_all_review_stats.csv', columns=['id','origId','at','repliedAt','score','thumbsUpCount','polarity','subjectivity','reviewLength'], \n",
    "               index = False,\n",
    "               header = (mode == 'w'),\n",
    "               mode = mode)\n",
    "    mode = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading 'score' dataframe\n",
    "df_stats = pd.read_csv(file_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date fields back to date\n",
    "df_stats['at'] = pd.to_datetime(df_stats['at'],format='%Y%m%d', errors='ignore')\n",
    "df_stats['repliedAt'] = pd.to_datetime(df_stats['repliedAt'],format='%Y%m%d', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it altogether as pickle for keeping the data types\n",
    "df_stats.to_pickle(''.join([file_to_base,'pkl']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read stats dataframe to check its structure\n",
    "df_stats = pd.read_pickle(''.join([file_to_base,'pkl']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 448167785 entries, 0 to 448167784\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   id             int64         \n",
      " 1   origId         int64         \n",
      " 2   at             datetime64[ns]\n",
      " 3   repliedAt      datetime64[ns]\n",
      " 4   score          int64         \n",
      " 5   thumbsUpCount  int64         \n",
      " 6   polarity       float64       \n",
      " 7   subjectivity   float64       \n",
      " 8   reviewLength   int64         \n",
      "dtypes: datetime64[ns](2), float64(2), int64(5)\n",
      "memory usage: 30.1 GB\n"
     ]
    }
   ],
   "source": [
    "df_stats.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
